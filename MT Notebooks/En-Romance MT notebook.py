#
# Credit  for the open-source translation models used in this notebook goes to the members of the
# OPUS-MT and Helsinki-NLP teams, as well as contributors to Microsoft's Marian-NMT, in partciular
# Jörg Tiedemann at the University of Helsinki and Marcin Junczys-Dowmunt at Microsoft Translation
#
# Inspiration for the sentiment models used in this notebook comes from Chris McCormick and
# Nick Ryan's BERT fine-tuning tutorial, located here: https://mccormickml.com/2019/07/22/BERT-fine-tuning/
#
# Our main contribution as the authors of this notebook and members of the associated project (anonymized
# for purposes of peer-review) is in incorporating the sentiment models described above (BERT/XLM-RoBERTa) directly
# into the process of selecting translation candidates generated by beam search, supported by the open-source
# translation models also described above
#
# Some comments——such as those giving credit to the contributors listed above——may not be our own, and
# should be credited to Chris McCormick, Nick Ryan, and various members of the OPUS-MT, Helsinki-NLP, and
# Marian-NMT teams

###########################################################################################################

# -*- coding: utf-8 -*-
"""MarianMT en-ROMANCE Model with sentiment-based modification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EBQTIVCwTXP7bBOjm0493pkGu_1FcNln
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install transformers --upgrade
# !pip install mosestokenizer

"""### Translating with Transformers
Thanks to everyone who helped with this, especially: 


*   [Jörg Tiedemann](https://researchportal.helsinki.fi/en/persons/j%C3%B6rg-tiedemann) from the [OPUS project](http://opus.nlpl.eu/)
*  [Marcin Junczys-Dowmunt](https://twitter.com/marian_nmt) from Microsoft's [Marian NMT](https://t.co/IuL994N6nQ?amp=1) library
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# from transformers import MarianMTModel, MarianTokenizer
# src_text = [
#     '>>fr<< This is a sentence in english that we want to translate to french.',
#     '>>pt<< This should go to portuguese.',
#     '>>es<< And this to Spanish.'
# ]
# 
# model_name = 'Helsinki-NLP/opus-mt-en-ROMANCE'
# tokenizer = MarianTokenizer.from_pretrained(model_name)
# # see tokenizer.supported_language_codes for choices
# model = MarianMTModel.from_pretrained(model_name)

#@title Translate with Transformers
english_text = "Time Warner Road Runner customer support here absolutely blows." #@param {type:"string"}
tgt_language = "es" #@param ["fr", "es", "it", "pt", "pt_br", "ro", "ca", "gl", "pt_BR", "la", "wa", "fur", "oc", "fr_CA", "sc", "es_ES", "es_MX", "es_AR", "es_PR", "es_UY", "es_CL", "es_CO", "es_CR", "es_GT", "es_HN", "es_NI", "es_PA", "es_PE", "es_VE", "es_DO", "es_EC", "es_SV", "an", "pt_PT", "frp", "lad", "vec", "fr_FR", "co", "it_IT", "lld", "lij", "lmo", "nap", "rm", "scn", "mwl"] {allow-input: true}

src_txt = f'>>{tgt_language}<< {english_text}'
translated = model.generate(**tokenizer.prepare_translation_batch([src_txt]), num_beams=10, num_return_sequences=10)
print([tokenizer.decode(t, skip_special_tokens=True) for t in translated])

import torch
from google.colab import drive
drive.mount("/content/drive")

!pip install transformers

from transformers import BertForSequenceClassification
english_sentiment_model = BertForSequenceClassification.from_pretrained(
    "bert-base-uncased", # Use the 12-layer BERT model, with an uncased vocab.
    num_labels = 2, # The number of output labels--2 for binary classification.
                    # You can increase this for multi-class tasks.   
    output_attentions = False, # Whether the model returns attentions weights.
    output_hidden_states = False # Whether the model returns all hidden-states.
)

from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig

# Load BertForSequenceClassification, the pretrained BERT model with a single 
# linear classification layer on top. 
spanish_sentiment_model = XLMRobertaForSequenceClassification.from_pretrained(
    "xlm-roberta-large", # Use the large XLM Roberta model.
    num_labels = 2, # The number of output labels--2 for binary classification, 3 for ternary, etc.
                    # You can increase this for multi-class tasks.   
    output_attentions = False, # Whether the model returns attentions weights.
    output_hidden_states = False, # Whether the model returns all hidden-states.
)

english_sentiment_model.load_state_dict(torch.load("/content/drive/My Drive/Summer Project 2020/English_sentiment_model.pt", map_location=torch.device('cpu')))

english_sentiment_model.eval()

spanish_sentiment_model.load_state_dict(torch.load("/content/drive/My Drive/Summer Project 2020/Spanish_sentiment_model.pt", map_location=torch.device('cpu')))

spanish_sentiment_model.eval()

from transformers import BertTokenizer, XLMRobertaTokenizer
from torch.utils.data import TensorDataset, DataLoader
import numpy as np
import re
from bs4 import BeautifulSoup

# gets the tweet into the format we want
def clean_tweet(tweet):
  tweet = BeautifulSoup(tweet, "lxml").get_text() # turns xml-formatted text into regular text
  tweet = re.sub(r"@[A-Za-z0-9]+", " ", tweet) # gets rid of all user references in tweets (i.e. "@username")
  tweet = re.sub(r"https?://[A-Za-z0-9./]+", " ", tweet) # gets rid of URLs
  tweet = re.sub(r"[^A-Za-z.!?áéíóúüñ¿ÁÉÍÓÚÜÑ']", " ", tweet) # gets rid of any non-standard characters in the tweets
  tweet = re.sub(r" +", " ", tweet) # replaces all excess whitespace with a single space

  return tweet # gives us our cleaned tweet

english_sentiment_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)

spanish_sentiment_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large', do_lower_case=True)

device = torch.device('cpu')

def predict_sentiment(tweet, language):

    if language == "english":
      sentiment_model = english_sentiment_model
      sentiment_tokenizer = english_sentiment_tokenizer
    if language == "spanish":
      sentiment_tokenizer = spanish_sentiment_tokenizer
      sentiment_model = spanish_sentiment_model
    
    tweet = clean_tweet(tweet)
    tweet_input_id = []
    tweet_attention_mask = []

    tweet_dict = sentiment_tokenizer.encode_plus(
                            tweet,                      # Sentence to encode.
                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'
                            max_length = 64,           # Pad & truncate all sentences.
                            truncation=True,           # Explicitly enable truncation
                            pad_to_max_length = True,
                            return_attention_mask = True,   # Construct attn. masks.
                            return_tensors = 'pt',     # Return pytorch tensors.
                       )

    # Add the encoded sentence to the list.    
    tweet_input_id.append(tweet_dict['input_ids'])

    # And its attention mask (simply differentiates padding from non-padding).
    tweet_attention_mask.append(tweet_dict['attention_mask'])

    # Convert the lists into tensors.
    tweet_input_id = torch.cat(tweet_input_id, dim=0)
    tweet_attention_mask = torch.cat(tweet_attention_mask, dim=0)

    tweet_data = TensorDataset(tweet_input_id, tweet_attention_mask)
    
    tweet_dataloader = DataLoader(tweet_data)
    
    for data in tweet_dataloader:
        tweet_input_id = data[0].to(device)
        tweet_attention_mask = data[1].to(device)
    
    tweet_logits = sentiment_model(tweet_input_id, token_type_ids=None, attention_mask=tweet_attention_mask)
    
    tweet_logits = tweet_logits[0].detach().cpu().numpy()

    tweet_logits = torch.Tensor(tweet_logits)

    softmax = torch.nn.Softmax(dim=1)
    prob_dist = softmax(tweet_logits)

    sentiment_pred = prob_dist.tolist()

    sentiment_pred = sentiment_pred[0][1]

    return sentiment_pred

print(predict_sentiment("This is the best day ever!", "english"))
print(predict_sentiment("Este es el peor dia de mi vida", "spanish"))


# OUR NOVEL CONTRIBUTION TO THE NMT CANDIDATE SELECTION PROCESS:
# Select, from the top num_candidates translations, the translation
# which minimizes the absolute difference between the translation's sentiment
# and that of the source text
def TranslateWithSentimentSelection(sentence, num_candidates):
  source_sentence = f'>>{"es"}<< {sentence}'
  translated = model.generate(**tokenizer.prepare_translation_batch([source_sentence]), num_beams=num_candidates, num_return_sequences=num_candidates)
  candidate_translations = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]
  
  source_sentiment = predict_sentiment(sentence, "english")
  target_sentiments = [predict_sentiment(candidate, "spanish") for candidate in candidate_translations]
  sentiment_divergence_list = []
  for i in range(len(target_sentiments)):
    sentiment_divergence_list.append(abs(target_sentiments[i] - source_sentiment))
  translation = candidate_translations[sentiment_divergence_list.index(min(sentiment_divergence_list))]
  
  return translation

# FOR GENERATING THE BASELINE TRANSLATION, I.E. BEST CANDIDATE AS DETERMINED BY
# BEAM SEARCH
def TranslateBaseline(sentence):
  source_sentence = f'>>{"es"}<< {sentence}'
  translated = model.generate(**tokenizer.prepare_translation_batch([source_sentence]))
  translation = ([tokenizer.decode(t, skip_special_tokens=True) for t in translated])[0]

  return translation

# Testing our modified model against the baseline

example_sentence_1 = "Time Warner Road Runner customer support here absolutely blows."
print("English sentence 1:", example_sentence_1)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_1))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_1, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_2 = "Okay, first assessment of the Kindle . . . it fucking rocks!"
print("English sentence 2:", example_sentence_2)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_2))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_2, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_3 = "Could Time Warner Cable suck more?"
print("English sentence 3:", example_sentence_3)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_3))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_3, 10))

example_sentence_4 = "LeBron is a monsta and he is only 24. SMH The world ain't ready."
print("English sentence 4:", example_sentence_4)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_4))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_4, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_5 = "I know my life has been flipped upside down when I just thought in my head that some Ramen sounds good. "
print("English sentence 5:", example_sentence_5)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_5))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_5, 10))


print("                                                                                   ")
print("                                                                                   ")
example_sentence_6 = "I'm sorry—I'm feeling kinda yucky myself—5am is going to come too quick."
print("English sentence 6:", example_sentence_6)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_6))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_6, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_7 = "I need a new boyfriend... I'm stuck in a rut"
print("English sentence 7:", example_sentence_7)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_7))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_7, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_8 = "aww that stinks!"
print("English sentence 8:", example_sentence_8)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_8))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_8, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_9 = "I'm tired. I feel like crap. And the world feels all crummy. Make me happy, USB disco mouse. "
print("English sentence 9:", example_sentence_9)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_9))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_9, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_10 = "why are people such wankers these days?"
print("English sentence 10:", example_sentence_10)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_10))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_10, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_11 = "@Holidaybot is rubbish! . . ."
print("English sentence 11:", example_sentence_11)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_11))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_11, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_12 = "@apple Contact sync between Yosemite and iOS8 is seriously screwed up. It used to be much more stable in the past"
print("English sentence 12:", example_sentence_12)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_12))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_12, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_13 = "Can't stand those ppl with @Apple stickers everywhere."
print("English sentence 13:", example_sentence_13)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_13))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_13, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_14 = "As a die hard @Apple customer, I must say I am truly displeased with the customer service I was given today."
print("English sentence 14:", example_sentence_14)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_14))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_14, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_15 = "Just broke my 3rd charger of the month. Get your shit together @apple"
print("English sentence 15:", example_sentence_15)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_15))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_15, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_16 = "Yo @Apple fix your shitty iMessage"
print("English sentence 16:", example_sentence_16)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_16))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_16, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_17 = "@apple please get yourself together! I need my products to work!"
print("English sentence 17:", example_sentence_17)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_17))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_17, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_18 = "@Apple the no caller ID thing is scary as heck and I suggest you stop it"
print("English sentence 18:", example_sentence_18)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_18))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_18, 10))

print("                                                                                   ")
print("                                                                                   ")
example_sentence_19 = "@Apple tbh annoyed with Apple's shit at the moment"
print("English sentence 19:", example_sentence_19)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_19))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_19, 10))

example_sentence_20 = "Fair enough. But i have the Kindle2 and I think it's perfect  :)"
print("English sentence 20:", example_sentence_20)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_20))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_20, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_21 = "how can you not love Obama? he makes jokes about himself."
print("English sentence 21:", example_sentence_21)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_21))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_21, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_22 = "Went to see the Star Trek movie last night.  Very satisfying."
print("English sentence 22:", example_sentence_22)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_22))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_22, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_23 = "I hate the dentist....who invented them anyways?"
print("English sentence 23:", example_sentence_23)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_23))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_23, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_24 = "@ Safeway. Place is a nightmare right now. Bumming."
print("English sentence 24:", example_sentence_24)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_24))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_24, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_25 = "Reading the tweets coming out of Iran... The whole thing is terrifying and incredibly sad..."
print("English sentence 25:", example_sentence_25)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_25))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_25, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_26 = "with the boyfriend, eating a quesadilla"
print("English sentence 26:", example_sentence_26)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_26))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_26, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_27 = "Hate safeway select green tea icecream! bought two cartons, what a waste of money. "
print("English sentence 27:", example_sentence_27)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_27))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_27, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_28 = "I am furious with Time Warner and their phone promotions!"
print("English sentence 28:", example_sentence_28)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_28))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_28, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_29 = "is upset about the whole GM thing. life as i know it is so screwed up"
print("English sentence 29:", example_sentence_29)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_29))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_29, 10))

print("                                                                                   ")
print("                                                                                   ")

example_sentence_30 = "saw night at the museum out of sheer desperation. who is funding these movies?"
print("English sentence 30:", example_sentence_30)
print("-----------------------------------------------------------------------------------")
print("Baseline model translation:", TranslateBaseline(example_sentence_30))
print("Modified model translation:", TranslateWithSentimentSelection(example_sentence_30, 10))
